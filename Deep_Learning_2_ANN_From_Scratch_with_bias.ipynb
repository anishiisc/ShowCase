{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# ANN From Scratch  with bias upgrades \n",
    "\n",
    "Ref\n",
    "\n",
    "https://heartbeat.fritz.ai/building-a-neural-network-from-scratch-using-python-part-1-6d399df8d432\n",
    "\n",
    "https://heartbeat.fritz.ai/building-a-neural-network-from-scratch-using-python-part-2-testing-the-network-c1f0c1c9cbb0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "479748ca-639b-4448-ae21-3681170a65de",
    "_uuid": "22d41ba02b32da646889dba983ba08c08cb38f08",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>serum_cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_ecg_results</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope of the peak</th>\n",
       "      <th>num_of_major_vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain  resting_blood_pressure  serum_cholestoral  \\\n",
       "0  70.0  1.0         4.0                   130.0              322.0   \n",
       "1  67.0  0.0         3.0                   115.0              564.0   \n",
       "2  57.0  1.0         2.0                   124.0              261.0   \n",
       "3  64.0  1.0         4.0                   128.0              263.0   \n",
       "4  74.0  0.0         2.0                   120.0              269.0   \n",
       "5  65.0  1.0         4.0                   120.0              177.0   \n",
       "6  56.0  1.0         3.0                   130.0              256.0   \n",
       "7  59.0  1.0         4.0                   110.0              239.0   \n",
       "8  60.0  1.0         4.0                   140.0              293.0   \n",
       "9  63.0  0.0         4.0                   150.0              407.0   \n",
       "\n",
       "   fasting_blood_sugar  resting_ecg_results  max_heart_rate_achieved  \\\n",
       "0                  0.0                  2.0                    109.0   \n",
       "1                  0.0                  2.0                    160.0   \n",
       "2                  0.0                  0.0                    141.0   \n",
       "3                  0.0                  0.0                    105.0   \n",
       "4                  0.0                  2.0                    121.0   \n",
       "5                  0.0                  0.0                    140.0   \n",
       "6                  1.0                  2.0                    142.0   \n",
       "7                  0.0                  2.0                    142.0   \n",
       "8                  0.0                  2.0                    170.0   \n",
       "9                  0.0                  2.0                    154.0   \n",
       "\n",
       "   exercise_induced_angina  oldpeak  slope of the peak  num_of_major_vessels  \\\n",
       "0                      0.0      2.4                2.0                   3.0   \n",
       "1                      0.0      1.6                2.0                   0.0   \n",
       "2                      0.0      0.3                1.0                   0.0   \n",
       "3                      1.0      0.2                2.0                   1.0   \n",
       "4                      1.0      0.2                1.0                   1.0   \n",
       "5                      0.0      0.4                1.0                   0.0   \n",
       "6                      1.0      0.6                2.0                   1.0   \n",
       "7                      1.0      1.2                2.0                   1.0   \n",
       "8                      0.0      1.2                2.0                   2.0   \n",
       "9                      0.0      4.0                2.0                   3.0   \n",
       "\n",
       "   thal  heart_disease  \n",
       "0   3.0              2  \n",
       "1   7.0              1  \n",
       "2   7.0              2  \n",
       "3   7.0              1  \n",
       "4   3.0              1  \n",
       "5   7.0              1  \n",
       "6   6.0              2  \n",
       "7   7.0              2  \n",
       "8   7.0              2  \n",
       "9   7.0              2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data read \n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# add header names\n",
    "headers =  ['age', 'sex','chest_pain','resting_blood_pressure',  \n",
    "        'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results',\n",
    "        'max_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak',\"slope of the peak\",\n",
    "        'num_of_major_vessels','thal', 'heart_disease']\n",
    "\n",
    "heart_df = pd.read_csv('heart.dat', sep=' ', names=headers)\n",
    "# Check \n",
    "heart_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape \n",
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        0\n",
       "sex                        0\n",
       "chest_pain                 0\n",
       "resting_blood_pressure     0\n",
       "serum_cholestoral          0\n",
       "fasting_blood_sugar        0\n",
       "resting_ecg_results        0\n",
       "max_heart_rate_achieved    0\n",
       "exercise_induced_angina    0\n",
       "oldpeak                    0\n",
       "slope of the peak          0\n",
       "num_of_major_vessels       0\n",
       "thal                       0\n",
       "heart_disease              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check nulls\n",
    "heart_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        float64\n",
       "sex                        float64\n",
       "chest_pain                 float64\n",
       "resting_blood_pressure     float64\n",
       "serum_cholestoral          float64\n",
       "fasting_blood_sugar        float64\n",
       "resting_ecg_results        float64\n",
       "max_heart_rate_achieved    float64\n",
       "exercise_induced_angina    float64\n",
       "oldpeak                    float64\n",
       "slope of the peak          float64\n",
       "num_of_major_vessels       float64\n",
       "thal                       float64\n",
       "heart_disease                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types \n",
    "heart_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and standardize \n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Create X data\n",
    "#------------------\n",
    "X = heart_df.drop(columns=['heart_disease'])\n",
    "\n",
    "# Create y data \n",
    "#------------------\n",
    "#1 means \"have heart disease\" and 0 means \"do not have heart disease\"\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(1, 0)\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(2, 1)\n",
    "\n",
    "#----------------\n",
    "y_label = heart_df['heart_disease'].values.reshape(X.shape[0], 1)\n",
    "\n",
    "\n",
    "#split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size=0.2, random_state=2)\n",
    "\n",
    "#standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    '''\n",
    "    A two layer neural network\n",
    "    '''\n",
    "        \n",
    "    def __init__(self, layers=[13,8,1], learning_rate=0.001, iterations=100):\n",
    "        self.params = {} # Dict initialize for Weights and Biases \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.loss = [] # Array initialize for losses at each iteration \n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "                \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Initialize the weights from a random normal distribution\n",
    "        '''\n",
    "        np.random.seed(1) # Seed the random number generator\n",
    "        self.params[\"W1\"] = np.random.randn(self.layers[0], self.layers[1]) \n",
    "        self.params['b1']  =np.random.randn(self.layers[1],)\n",
    "        self.params['W2'] = np.random.randn(self.layers[1],self.layers[2]) \n",
    "        self.params['b2'] = np.random.randn(self.layers[2],)\n",
    "        \n",
    "    def relu(self,Z):\n",
    "        '''\n",
    "        The ReLu activation function is to performs a threshold\n",
    "        operation to each input element where values less \n",
    "        than zero are set to zero.\n",
    "        '''\n",
    "        return np.maximum(0,Z)\n",
    "    \n",
    "    def dRelu(self, x):\n",
    "        '''\n",
    "        Derivative of ReLu \n",
    "        '''\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "    \n",
    "    def sigmoid(self,Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1/(1+np.exp(-Z))   \n",
    "\n",
    "    def eta(self, x):\n",
    "        ETA = 0.0000000001\n",
    "        return np.maximum(x, ETA)\n",
    "\n",
    "    def entropy_loss(self,y, yhat):\n",
    "        nsample = len(y)\n",
    "        yhat_inv = 1.0 - yhat\n",
    "        y_inv = 1.0 - y\n",
    "        yhat = self.eta(yhat) ## clips value to avoid NaNs in log\n",
    "        yhat_inv = self.eta(yhat_inv) \n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((y_inv), np.log(yhat_inv))))\n",
    "        return loss\n",
    "    \n",
    "    def mse_loss(self,y, y_hat):\n",
    "        loss = 1 / 2 * np.mean((y - y_hat)**2)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def forward_propagation(self):\n",
    "        '''\n",
    "        Performs the forward propagation\n",
    "        '''\n",
    "        \n",
    "        Z1 = self.X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y,yhat)\n",
    "\n",
    "        # save calculated parameters     \n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "\n",
    "        return yhat,loss\n",
    "    \n",
    "    \n",
    "    def back_propagation(self,yhat):\n",
    "        '''\n",
    "        Computes the derivatives and update weights and bias accordingly.\n",
    "        '''\n",
    "        y_inv = 1 - self.y\n",
    "        yhat_inv = 1 - yhat\n",
    "        # Note yhat = sigmoid(z2) \n",
    "        # Note sigmoid_prime(x) = sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "        # Define the Individual derivatives \n",
    "        dl_wrt_yhat  = np.divide(y_inv, self.eta(yhat_inv)) - np.divide(self.y, self.eta(yhat))\n",
    "        dyhat_wrt_z2 = yhat*(yhat_inv)\n",
    "        dz2_wrt_A1   = self.params['W2']\n",
    "        dA1_wrt_z1   = self.dRelu(self.params['Z1'])\n",
    "        dz1_wrt_w1   = self.X\n",
    "        dz2_wrt_w2  = self.params['A1']\n",
    "        \n",
    "        # Now from chain rule of calculus we have \n",
    "        #--------------------------------------------------\n",
    "        ##  dl_wrt_w2 = dl_wrt_yhat*dyhat_wrt_z2*dz2_wrt_w2\n",
    "        #--------------------------------------------------\n",
    "        # Now following Matrix multiplication rules we have \n",
    "        # define delta2 \n",
    "        delta2 = np.multiply(dl_wrt_yhat,dyhat_wrt_z2)\n",
    "        # Compute derivatives with respect to outer Weight Matrix \n",
    "        dl_wrt_w2 = np.dot(dz2_wrt_w2.T,(delta2))\n",
    "        \n",
    "        # Again from chain rule we have \n",
    "        #--------------------------------------------------\n",
    "        ## dl_wrt_w1 = dl_wrt_yhat*dyhat_wrt_z2*dz2_wrt_A1*dA1_wrt_z1*dz1_wrt_w1\n",
    "        #--------------------------------------------------\n",
    "        # Now following Matrix Multiplication rules we define\n",
    "        \n",
    "        delta1 = (np.dot(delta2,dz2_wrt_A1.T))*dA1_wrt_z1\n",
    "        # Compute derivatives with respect to inner  Weight Matrix \n",
    "        dl_wrt_w1 = np.dot(dz1_wrt_w1.T,delta1)\n",
    "        \n",
    "        #--------------------------------------------------\n",
    "        # Now compute derivates with respect to bias \n",
    "        #---------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # Outer Bias derivates : Following chain rule we have \n",
    "        #------------------------\n",
    "        # dl_wrt_b2 = dl_wrt_yhat*dyhat_wrt_z2*dz2_wrt_b2\n",
    "        #------------------------\n",
    "        # Note:  dz2_wrt_b2 = [1]\n",
    "        dl_wrt_b2 = np.sum(delta2, axis=0,keepdims=True)\n",
    "        \n",
    "        \n",
    "        # Inner Bias derivatives : Following chain  rule we have \n",
    "        #------------------------\n",
    "        # dl_wrt_b1 = dl_wrt_yhat*dyhat_wrt_z2*dz2_wrt_A1*dA1_wrt_z1*dz1_wrt_b1\n",
    "        #------------------------\n",
    "        # Note : dz1_wrt_b1 = 1 \n",
    "        dl_wrt_b1 = np.sum(delta1,axis=0,keepdims = True)\n",
    "        \n",
    "        \n",
    "        #update the weights and bias\n",
    "        self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1\n",
    "        self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2\n",
    "        self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "        self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Trains the neural network using the specified data and labels\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts on a test data\n",
    "        '''\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred)\n",
    "    \n",
    "    \n",
    "    def acc(self, y, yhat):\n",
    "        '''\n",
    "        Calculates the accutacy between the predicted valuea and the truth labels\n",
    "        '''\n",
    "        acc = int(sum(y == yhat) / len(y) * 100)\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss curve\n",
    "        '''\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet() # create the NN model\n",
    "nn.fit(Xtrain, ytrain) #train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 87\n",
      "Test accuracy is 75\n"
     ]
    }
   ],
   "source": [
    "### Getting Accuracies\n",
    "train_pred = nn.predict(Xtrain)\n",
    "test_pred = nn.predict(Xtest)\n",
    "\n",
    "print(\"Train accuracy is {}\".format(nn.acc(ytrain, train_pred)))\n",
    "print(\"Test accuracy is {}\".format(nn.acc(ytest, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
