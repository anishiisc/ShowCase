{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Linear Reg with Mini Batch Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCES\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/\n",
    "\n",
    "https://realpython.com/gradient-descent-algorithm-python/\n",
    "\n",
    "https://towardsdatascience.com/implementing-sgd-from-scratch-d425db18a72c\n",
    "\n",
    "https://www.pyimagesearch.com/2016/10/17/stochastic-gradient-descent-sgd-with-python/\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/?ref=rp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent and its Variants \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Concept**\n",
    "\n",
    "In machine learning, gradient descent is an optimization technique used for computing the model parameters (coefficients and bias) for algorithms like linear regression, logistic regression, neural networks, etc. In this technique, we repeatedly iterate through the training set and update the model parameters in accordance with the gradient of error with respect to the training set.\n",
    "\n",
    "**Types of Gradient descent**\n",
    "\n",
    "- **Batch Gradient Descent :**\n",
    "\n",
    "     - Parameters are updated after computing the gradient of error with respect to the entire training set\n",
    "     - Since entire training data is considered before taking a step in the direction of gradient, therefore it takes a lot of time for making a single update.\n",
    "    - It makes smooth updates in the model parameters\n",
    "\n",
    "- **Stochastic Gradient Descent:** \n",
    "\n",
    "     - Parameters are updated after computing the gradient of error with respect to a single training example\n",
    "     - Since only a single training example is considered before taking a step in the direction of gradient, we are forced to loop over the training set and thus cannot exploit the speed associated with vectorizing the code.\n",
    "     - It makes very noisy updates in the parameters\n",
    "     \n",
    "- **Mini-Batch Gradient Descent:** \n",
    "\n",
    "     - Parameters are updated after computing the gradient of error with respect to a subset of the training set\n",
    "     - Since a subset of training examples is considered, it can make quick updates in the model parameters and can also exploit the speed associated with vectorizing the code.\n",
    "     - Depending upon the batch size, the updates can be made less noisy – greater the batch size less noisy is the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Stochastic Concept vis a vis Plain Batch Gradient Descent \n",
    "\n",
    "**Stochastic**\n",
    "The word ‘stochastic‘ means a system or a process that is linked with a random probability. Hence, in Stochastic Gradient Descent, a few samples are selected randomly instead of the whole data set for each iteration. \n",
    "\n",
    "**Batch**\n",
    "In Gradient Descent, there is a term called “batch” which denotes the total number of samples from a dataset that is used for calculating the gradient for each iteration. \n",
    "\n",
    "In typical Gradient Descent optimization, like Batch Gradient Descent, the batch is taken to be the whole dataset. Although, using the whole dataset is really useful for getting to the minima in a less noisy and less random manner, but the problem arises when our datasets gets big.\n",
    "\n",
    "**Why Batch is inefficient for large data sets**\n",
    "Suppose, you have a million samples in your dataset, so if you use a typical Gradient Descent optimization technique, you will have to use all of the one million samples for completing one iteration while performing the Gradient Descent, and it has to be done for every iteration until the minima is reached. Hence, it becomes computationally very expensive to perform.\n",
    "\n",
    "**Stochastic Gradient Descent to the rescue**\n",
    "This problem is solved by Stochastic Gradient Descent. In SGD, it uses only a single sample, i.e., a batch size of one, to perform each iteration. The sample is randomly shuffled and selected for performing the iteration.\n",
    "\n",
    "**SGD : Noisy but faster?**\n",
    "So, in SGD, we find out the gradient of the cost function of a single example at each iteration instead of the sum of the gradient of the cost function of all the examples.\n",
    "\n",
    "In SGD, since only one sample from the dataset is chosen at random for each iteration, the path taken by the algorithm to reach the minima is usually noisier than your typical Gradient Descent algorithm. But that doesn’t matter all that much because the path taken by the algorithm does not matter, as long as we reach the minima and with significantly shorter training time.\n",
    "\n",
    "**Balance between speed and Noise?**\n",
    "The mini-batch gradient descent makes a compromise between the speedy convergence and the noise associated with gradient update which makes it a more flexible and robust algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mini Batch Algorithm \n",
    "\n",
    "Let theta = model parameters and max_iters = number of epochs.\n",
    "\n",
    "for itr = 1, 2, 3, …, max_iters:\n",
    "\n",
    "      Select Randomly a Batch of 'K= batch size') \n",
    "      for mini_batch (X_mini, y_mini):\n",
    "\n",
    "**Forward Pass on the batch X_mini:**\n",
    "\n",
    "  Make predictions on the mini-batch\n",
    "  \n",
    "  Compute error in predictions (J(theta)) with the current values of the parameters\n",
    "  \n",
    "**Backward Pass:**\n",
    "\n",
    "  Compute gradient(theta) = partial derivative of J(theta) w.r.t. theta\n",
    "  \n",
    "  Update parameters:\n",
    "  theta = theta – learning_rate*gradient(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "479748ca-639b-4448-ae21-3681170a65de",
    "_uuid": "22d41ba02b32da646889dba983ba08c08cb38f08",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "\n",
    "**References**\n",
    "https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/\n",
    "\n",
    "https://medium.com/data-science-365/linear-regression-with-gradient-descent-895bb7d18d52\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Advertising dataset captures sales revenue generated with respect to advertisement spends across multiple channels like radio, TV and newspaper. As you can see, there are four columns in the dataset. Since our problem definition involves only sales and TV columns in the dataset, we do not need radio and newspaper columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Sales\n",
       "0  230.1   22.1\n",
       "1   44.5   10.4\n",
       "2   17.2    9.3\n",
       "3  151.5   18.5\n",
       "4  180.8   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unwanted columns \n",
    "df.drop(columns=['Radio','Newspaper'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TV       0\n",
       "Sales    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialization \n",
    "\n",
    "We know that equation of a simple linear regression is expressed as:\n",
    "\n",
    "$$ \\hat{y} = mx + b  $$\n",
    "\n",
    "Thus, we have two parameters $m$ and $b$.  We store both of these parameter $m$ and $b$ in an array called theta. First, we initialize theta with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X, Y , Theta \n",
    "#---------------------------\n",
    "N = df['Sales'].values.size  # number of observations \n",
    "x = np.append(np.ones((N,1)),df['TV'].values.reshape(N,1),axis=1)\n",
    "y = df['Sales'].values.reshape(N,1)\n",
    "theta = np.zeros((2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 2) (40, 2) (160, 1) (40, 1)\n"
     ]
    }
   ],
   "source": [
    "# test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function \n",
    "\n",
    "\n",
    "Mean Squared Error (MSE) of Regression is given as:\n",
    "\n",
    "$$J=\\frac{1}{2N} \\sum_{i=1}^{N}(y-\\hat{y})^{2} -- (2) $$\n",
    "\n",
    "\n",
    "Where $N$ is the number of training samples, $y$ is the actual value and $\\hat{y}$ is the predicted value.\n",
    "\n",
    "The above loss function can be implemented as:\n",
    "\n",
    "We feed the data and the model parameter theta to the loss function which returns the MSE. Remember, data[,0] has $x$ value and data[,1] has $y$ value. Similarly, theta [0] has a value of $m$ and theta[1] has a value of $b$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define predict function \n",
    "def predict(x,theta):\n",
    "    y_pred = np.dot(x,theta)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function \n",
    "def mse_loss(x,Y,theta):\n",
    "    y_pred = np.dot(x,theta)\n",
    "    sqrd_err = (Y - y_pred)**2\n",
    "    loss = (1/(2*N))*np.sum(sqrd_err)\n",
    "    return loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to minimize this loss. In order to minimize the loss, we need to calculate the gradient of the loss function $J$ with respect to the model parameters $m$ and $b$ and update the parameter according to the parameter update rule. So, first, we will calculate the gradient of the loss function.\n",
    "\n",
    "\n",
    "**NOTE**\n",
    "For Mini Batch Gradient Descent : The summation is for all rows for the mini batch chosen currently \n",
    "\n",
    "\n",
    "### Gradients of Loss Function \n",
    "\n",
    "\n",
    "Gradients of loss function $J$ with respect to parameter $m$ is given as:\n",
    "\n",
    "\n",
    "$$ \\frac{d J}{d m}=\\frac{2}{N} \\sum_{i=1}^{N}-x_{i}\\left(y_{i}-\\left(m x_{i}+b\\right)\\right) -- (3) $$\n",
    "\n",
    "\n",
    "Gradients of loss function $J$ with respect to parameter $b$ is given as:\n",
    "\n",
    "\n",
    "$$ \\frac{d J}{d b}=\\frac{2}{N} \\sum_{i=1}^{N}-\\left(y_{i}-\\left(m x_{i}+b\\right)\\right) -- (4) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Update Rule\n",
    "\n",
    "After computing gradients we need to update our model paramater according to our update rule as given below:\n",
    "\n",
    "$$m=m-\\alpha \\frac{d J}{d m} -- (5) $$ \n",
    "\n",
    "$$ b=b-\\alpha \\frac{d J}{d b} --(6) $$\n",
    "\n",
    "\n",
    "Since we stored $m$ in theta[0] and $b$ in theta[1], we can write our update equation as: \n",
    "\n",
    "$$\\theta = \\theta - \\alpha \\frac{dJ}{d\\theta} -- (7) $$\n",
    "\n",
    "As we learned in the previous section, updating gradients for just one time will not lead us to the convergence i.e minimum of the cost function, so we need to compute gradients and the update the model parameter for several iterations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Stochastic Gradient Descent function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stochastic_Gradient_Desc(x,Y,learn_rate=0.000068,num_iter=400000,batch_size=64):\n",
    "    losses = []\n",
    "    theta = np.zeros((2,1))\n",
    "    temp_data = np.hstack((x,Y))\n",
    "    np.random.shuffle(temp_data)\n",
    "    for i in range(num_iter):\n",
    "        # Randomly Select a batch from temp_data \n",
    "        number_of_rows = temp_data.shape[0]\n",
    "        random_indices = np.random.choice(number_of_rows, size=batch_size, replace=False)\n",
    "        data = temp_data[random_indices, :]\n",
    "        ydata = data[:,-1].reshape(data.shape[0],1)\n",
    "        xdata = data[:,0:x.shape[1]]\n",
    "\n",
    "        # Forward Pass : Predict \n",
    "        y_pred = predict(xdata,theta)\n",
    "        # Compute Loss at current theta value \n",
    "        loss = mse_loss(xdata,ydata,theta)\n",
    "        \n",
    "        # Compute derivatives \n",
    "        der = np.dot(xdata.transpose(),(y_pred-ydata))/N\n",
    "        theta -= learn_rate*der\n",
    "        #print(theta)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return theta, losses,learn_rate    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.27547202]\n",
      " [0.0528532 ]]\n"
     ]
    }
   ],
   "source": [
    "# Train SGD \n",
    "theta, losses,alpha = Stochastic_Gradient_Desc(X_train,y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses,alpha):\n",
    "    fig, ax = plt.subplots(figsize = (9,6))\n",
    "    ax.plot(losses)\n",
    "    ax.set_title(\"Grad Descent loss values Vs iterations\",pad=20,size=18,color='gray')\n",
    "    ax.set_ylabel(\"losses for  Learning rate =\" + str(alpha))\n",
    "    ax.set_xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(losses,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function \n",
    "def get_accuracy(y_pred,y):\n",
    "    y_mean = y.mean()\n",
    "    # Coeff of determination - R squared : Pearson correlation is chosen between y and y_pred\n",
    "    corrmat = np.corrcoef(y.flatten(),y_pred.flatten())\n",
    "    pearson_corr = corrmat[0,1]\n",
    "    R_sq = pearson_corr**2\n",
    "    # Mean Square Error \n",
    "    MSE = ((y - y_pred)**2).mean()\n",
    "    # Root Mean Square Error \n",
    "    RMSE = np.sqrt(MSE)\n",
    "    accu_dict = {\"R_sq\":[np.round(R_sq,2)],\"RMSE\":[np.round(RMSE,2)]}\n",
    "    return accu_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(accu_dict):\n",
    "    accu_df = pd.DataFrame(accu_dict)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.colheader_justify', 'center')\n",
    "    pd.set_option('display.precision', 2)\n",
    "    display(accu_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_sq</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.59</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_sq  RMSE\n",
       "0  0.59  3.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on train data \n",
    "y_pred_train = predict(X_train,theta)\n",
    "# get accuracy\n",
    "accu_dict_train = get_accuracy(y_pred_train,y_train)\n",
    "df1 = pd.DataFrame.from_dict(accu_dict_train)\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_sq</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.68</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_sq  RMSE\n",
       "0  0.68  3.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test data \n",
    "y_pred_test = predict(X_test,theta)\n",
    "# get accuracy\n",
    "accu_dict_test = get_accuracy(y_pred_test,y_test)\n",
    "df2 = pd.DataFrame.from_dict(accu_dict_test)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
